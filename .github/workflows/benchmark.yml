name: Benchmark Pipeline

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  schedule:
    - cron: '0 0 1 * *'  # Run at midnight on the 1st of every month

jobs:
  benchmark:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        script: [bench_ols.R, bench_poisson.R, bench_logit.R]
    steps:
    
    - name: Checkout repository
      uses: actions/checkout@v4

    # R
    
    - name: Install libpng-dev
      run: sudo apt-get update && sudo apt-get install -y libpng-dev
    
    - name: Setup R
      uses: r-lib/actions/setup-r@v2
      with:
        r-version: '4.4.0'
        use-public-rspm: true
    
    - name: Install pandoc
      uses: r-lib/actions/setup-pandoc@v2
    
    - name: Setup renv
      uses: r-lib/actions/setup-renv@v2
      with:
        cache-version: 2
    
    - name: Configure R compilation flags
      run: |
        mkdir -p ~/.R
        echo "CFLAGS   = -g -O3 -mtune=native" > ~/.R/Makevars
        echo "CXXFLAGS = -g -O3 -mtune=native" >> ~/.R/Makevars

    # Julia
    
    - name: Setup Julia
      uses: julia-actions/setup-julia@v2
      with:
        version: '1.11.6'
    
    - name: Cache Julia pacakges
      uses: julia-actions/cache@v2
    
    - name: Install Julia packages
      run: |
        julia --project=. -e 'using Pkg; Pkg.activate("."); Pkg.instantiate();'

    - name: set julia thread count
      run: echo "JULIA_NUM_THREADS=2" >> $GITHUB_ENV

    # Python
    
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
    
    - name: Create virtual environment
      run: |
        python -m venv .venv
    
    - name: Install Python packages
      run: |
        source .venv/bin/activate
        pip install --upgrade pip
        pip install pandas pyfixest
    
    - name: Make venv available to subsequent steps
      run: |
        source .venv/bin/activate
        echo "VIRTUAL_ENV=$VIRTUAL_ENV" >> $GITHUB_ENV
        echo "$VIRTUAL_ENV/bin" >> $GITHUB_PATH

    - name: set numba parallel flags
      run: echo "NUMBA_NUM_THREADS=2" >> $GITHUB_ENV

    # RUN BENCHMARK
    
    - name: Run benchmark
      run: |
        source .venv/bin/activate
        Rscript ${{ matrix.script }}

    ## Upload results as artifacts
    
    - name: Upload benchmark results
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ matrix.script }}
        path: results/${{ matrix.script == 'bench_ols.R' && 'bench_ols*.csv' || matrix.script == 'bench_poisson.R' && 'bench_poisson*.csv' || 'bench_logit*.csv' }}
        retention-days: 1

  summarize:
    needs: benchmark
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # R
      
      - name: Install libpng-dev
        run: sudo apt-get update && sudo apt-get install -y libpng-dev
      
      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: 'release'
          use-public-rspm: true
      
      - name: Install pandoc
        uses: r-lib/actions/setup-pandoc@v2
      
      - name: Configure R compilation flags
        run: |
          mkdir -p ~/.R
          echo "CFLAGS   = -g -O3 -mtune=native" > ~/.R/Makevars
          echo "CXXFLAGS = -g -O3 -mtune=native" >> ~/.R/Makevars

      - name: Setup renv
        uses: r-lib/actions/setup-renv@v2
        with:
          cache-version: 3

      # Python
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
      
      - name: Create virtual environment
        run: |
          python -m venv .venv
      
      - name: Install Python packages
        run: |
          source .venv/bin/activate
          pip install --upgrade pip
          pip install pandas pyfixest
      
      - name: Make venv available to subsequent steps
        run: |
          source .venv/bin/activate
          echo "VIRTUAL_ENV=$VIRTUAL_ENV" >> $GITHUB_ENV
          echo "$VIRTUAL_ENV/bin" >> $GITHUB_PATH

      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          pattern: benchmark-results-*
          path: results/
          merge-multiple: true
      
      - name: Summarize results
        run: |
          source .venv/bin/activate
          Rscript summarize_benchmark.R
      
      - name: Upload summarized results
        uses: actions/upload-artifact@v4
        with:
          name: summarized-results
          path: results/
          retention-days: 1

      - name: Configure git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

      - name: Commit and push results
        run: |
          # Check if there are any changes
          if git diff --quiet && git diff --cached --quiet; then
            echo "No changes to commit"
            exit 0
          fi
          
          # Add changes
          git add results/
          git add README.md
          
          # Check again if there are changes after staging
          if git diff --cached --quiet; then
            echo "No changes to commit after staging"
            exit 0
          fi
          
          # Commit changes
          git commit -m "Update benchmark results [skip ci]
          
          - Updated from OLS, Poisson, and Logit benchmark workflows
          - Commit SHA: ${{ github.sha }}
          - Workflow run: ${{ github.run_id }}"
          
          # Push changes
          git push origin ${{ github.ref_name }}
          
          echo "Successfully committed and pushed benchmark results"
